{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее  задание  № 1.  \n",
    "*Графематический и морфологический анализ текста*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Фейгина Анастасия**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вариант D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:**\n",
    "\n",
    "Вычислить и проанализировать статистику морфологической омонимии в РЯ, взяв для этого 2-3 текста разных стилей/жанров\n",
    "и составив программу, которая на базе выбранного, программно подключаемого морфопроцессора определяет:\n",
    "\n",
    "– общее количество словоупотреблений, число различных словоформ, количество уникальных лемм, число незнакомых слов,\n",
    "коэффициент лексического богатства текста (= отношение числа различных лемм к общему числу словоупотреблений);\n",
    "\n",
    "–  абсолютную и относительную (с учетом/без учета неизменяемых слов) частоту омонимичных словоформ, абсолютную и\n",
    "относительную частоту словоформ с лексико-морфологической омонимией, максимальное и среднее число омонимов у \n",
    "словоформ текста, словоформы с наибольшим числом омонимов, наиболее частотный омоним\n",
    "\n",
    "В качестве подключаемого морфопроцессора можно взять, например:\n",
    "  mystem(http://api.yandex.ru/mystem/downloads/) или АОТ (http://www.aot.ru )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проведения анализа были выбраны 2 текста разных жанров (научный и художественный). Тексты приведены в файлах kuprin.txt, neuron.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве подключаемого морфопроцессора я выбрала Mystem и pymorphy2 (https://pymorphy2.readthedocs.org/en/latest/#). \n",
    "\n",
    "В первом случае выбор обоснован интересом к продукции Яндекса, второй - более широким функционалом. Поэтому часть заданий реализовано с помощью Mystem, а другая часть с помощью Pymorph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовка данных:**\n",
    "\n",
    "Прежде чем начинать анализировать данные, нужно их \"почистить\", привести в удобный для работы вид. Изначально мы имеем тесты со знаками препинания, цифрами, пробелами и другими символами. Нас интересуют лишь слова, поэтому была написана функция *make_clear_text*. Рассмотрим ее работу подробнее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# подключение необходимых библиотек\n",
    "import pymorphy2\n",
    "from texts import *\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_clear_text(text):\n",
    "    # текст без спец символов/цифр/пунктуации\n",
    "    m = Mystem()\n",
    "    clear_text = []\n",
    "    # переводим все заглавные буквы в строчные\n",
    "    lm = m.analyze(text.lower())\n",
    "    for i in range(0, len(lm)):\n",
    "        # в этом месте мы отбрасываем все посторонные символы, остается массив слов\n",
    "        if 'analysis' in lm[i]:\n",
    "            clear_text.append(lm[i]['text'])\n",
    "    return clear_text\n",
    "\n",
    "def no_one_symbol_text(text):\n",
    "    # убираем слова состоящие из одного символа\n",
    "    new_text = list(text)\n",
    "    for i in text:\n",
    "        if len(i) <= 1:\n",
    "            new_text.remove(i)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для написания этой функции был использован морфологический процессор Mystem. Он анализирует все элементы текста, расставляя тег \"analysis\" только словам, игнорируя все остальные символы. Этим я и воспользовалась. Хотя изначально была идея использовать регулярные выражения. \n",
    "Теперь все готово для проведения анализа, начнем с **общего количества совоупотреблений**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def usage_count(text):\n",
    "    # общее количество словоупотреблений\n",
    "    # приводим данные в удобный вид, считаем, сколько слов в нашем тексте\n",
    "    result = len(make_clear_text(text))\n",
    "    print(\"Общее количество словоупотреблений: \", result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее реализована функция, которая считает **количество различных словоформ**. Для этого необходимо сделать множество словоупотреблений, таким образом мы уберем повторяющиеся элементы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_different_word_forms(text):\n",
    "    # число различных словоформ\n",
    "    # приводим данные в удобный вид, получаем список всех слов в тексте\n",
    "    clear_text = make_clear_text(text)\n",
    "    # находим множество всех слов в тексте (теперь нет повторяющихся слов) и посчитаем их количество\n",
    "    result = len(set(clear_text))\n",
    "    print(\"Число различных словоформ: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь реализуем функцию подсчитывающую **количество уникальных лемм**. Здесь я использовала морфопроцессор Mystem чтобы найти леммы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_of_unique_lemmas(text):\n",
    "    # количество уникальных лемм\n",
    "    m = Mystem()\n",
    "    # текст с леммами\n",
    "    lemmas = m.lemmatize(text)\n",
    "    # делим текст на слова\n",
    "    lemmatized_text = ''.join(lemmas)\n",
    "    # чистим данные от лишних символов\n",
    "    clear_text = no_one_symbol_text(make_clear_text(lemmatized_text))\n",
    "    result = len(set(clear_text))\n",
    "    print(\"Количество уникальных лемм: \", result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим пунктом найдем **количество неизвестных слов**. У морфопроцессора **pymorph** есть очень удобная функция **word_is_known(word)**, она возвращает **True**, если слово известно, иначе - **False**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_of_unknown_words(text):\n",
    "    # число незнакомых слов\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    clear_text = set(no_one_symbol_text(make_clear_text(text)))\n",
    "    # суммируем количество неизвестных слов\n",
    "    result = sum([not morph.word_is_known(x) for x in clear_text])\n",
    "    print(\"Число незнакомых слов: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее рассмотрим метод вычисления коэффициента **лексического богатства текста**. Здесь очень просто, потому что мы уже умеем считать количество уникальных лемм и общее количество словоупотреблений. Осталось только разделить их друг на друга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexical_richness_of_the_text_index(text):\n",
    "    # коэффициент лексического богатства текста\n",
    "    result = number_of_unique_lemmas(text)/usage_count(text)\n",
    "    print(\"Коэффициент лексического богатства текста:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим функцию **абсолютной и относительной частоты омонимичных словоформ** без учета неизменяемых слов. Здесь нам нужно посчитать все слова у которых парсер выдает более одного типа разбора + надо учесть и отбросить те омонимы, у которых лексемы одинаковые. Для этого мы берем очередной омоним и склоняем все его разборы, чтобы найти лексемы. Далее находим множества этих лексем, и если оказывается, что в таких множествах 1 элемент - такой омоним неизменяемый, мы его отбрасываем. Но такой способ не всегда срабатывает. Существуют сокращениях слов (например \"руб\" - рубль), \"руб\" является неизменяемым омонимом, но когда мы начнем его склонять, морфопроцессор посчитает, что это \"рубль\", и склонять мы будем уже совсем не то, что хотели. Поэтому будем использовать встроенный в морфопроцессор тег m.tag если в нем есть параметр Fixd, то это неизменяемое слово. Опытным путем подтвердилось, что такой тег гарантирует работу для сокращений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frequency_homonymous_word_forms(text):\n",
    "    # абсолютная и относительная (без учета/с учетом неизменяемых слов) частота омонимичных словоформ\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    result = 0\n",
    "    clear_text = set(no_one_symbol_text(make_clear_text(text)))\n",
    "    for j in clear_text:\n",
    "        m = morph.parse(j)\n",
    "        for k in range(0, len(m)):\n",
    "            lexeme = []\n",
    "            unchangeable_tag = []\n",
    "            unchangeable_tag.append('Fixd' in m[k].tag)\n",
    "            unchangeable = []\n",
    "            lex = m[k].lexeme\n",
    "            for i in lex:\n",
    "                lexeme.append(i.word)\n",
    "            lexeme = set(lexeme)\n",
    "            unchangeable.append(len(lexeme) == 1)\n",
    "        unchangeable = unchangeable + unchangeable_tag\n",
    "        if len(m) > 1 and True not in unchangeable and morph.word_is_known(j):\n",
    "            result += 1\n",
    "    print(\"Абсолютная частота омонимичных словоформ без учета неизменяемых слов: \", result)\n",
    "    print(\"Относительная частота омонимичных словоформ без учета неизменяемых слов: \", result/len(make_clear_text(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция **абсолютной и относительной частоты омонимичных словоформ** c учетом неизменяемых слов. С учетом неизменяемых слов все эти действия просто не выполняем, нас интересуют как неизменяемые так и изменяемые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frequency_homonymous_word_forms_full(text):\n",
    "    # абсолютная и относительная (с учетом неизменяемых слов) частота омонимичных словоформ\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    result = 0\n",
    "    clear_text = set(no_one_symbol_text(make_clear_text(text)))\n",
    "    for j in clear_text:\n",
    "        m = morph.parse(j)\n",
    "        if len(m) > 1 and morph.word_is_known(j):\n",
    "            result += 1\n",
    "    print(\"Абсолютная частота омонимичных словоформ с учетом неизменяемых слов: \", result)\n",
    "    print(\"Относительная частота омонимичных словоформ с учетом неизменяемых слов: \", result/len(make_clear_text(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лексико-морфологическая омонимя - совпадение словоформ двух разных лексем. Применив метод parse к очередному слову, получаем список разборов (для омонимов), в каждом таком разборе имеется различная информация, в том числе и некий индивидуальный номер. Если у слов совпадают эти номера, то и лексемы у них одинаковые. В данном методе необходимо проверить номера всех разборов слова, и если они не совпадают, то такой омоним нам подходит. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frequency_of_word_forms_with_lexicalmorphological_homonymy(text):\n",
    "    # абсолютная и относительнаю частота словоформ с лексико-морфологической омонимией\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    result = 0\n",
    "    clear_text = set(no_one_symbol_text(make_clear_text(text)))\n",
    "    set_of_lexem = []\n",
    "    for j in clear_text:\n",
    "        m = morph.parse(j)\n",
    "        if morph.word_is_known(j):\n",
    "            set_of_lexem = set([m[i][4][0][2] for i in range(0, len(m))])\n",
    "        if len(m) > 1 and len(set_of_lexem) > 1:\n",
    "            result += 1\n",
    "    print(\"Абсолютная частота словоформ с лексико-морфологической омонимией: \", result)\n",
    "    print(\"Относительная частота словоформ с лексико-морфологической омонимией: \", result/len(make_clear_text(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь рассмотрим функцию, которая находит **максимальное и среднее число омонимов у словоформ текста, словоформу с наибольшим числом омонимов, наиболее частотный омоним**.\n",
    "\n",
    "Для того чтобы найти максимальное число омонимов нужно запоминать текущее число омонимов у очередного слова и сравнимать с предыдущим максимальным числом, если текущее больше чем предыдущее, сделаем его максимальным и так далее. Перебрав таким образом все слова, надем максимум.\n",
    "\n",
    "Чтобы найти среднее нужно просто суммировать количество омонимов каждого слова потом разделить на их количество.\n",
    "\n",
    "Словоформа с наибольшим числом омонимов находится как и максимальное число омонимов: мы просто каждый раз запоминаем слово вместе с числом.\n",
    "\n",
    "С наиболее частотным омонимом дела обстоят сложнее, тут нужно хранить словарик, у которого ключи это слова, а значения ключей - число, означающее сколько раз нам такое слово встретилось. Если слово нам еще не встречалось, мы добавляем в словарь новый ключ, если слово оказалось омонимом, то значение этого ключа увеличивается на единицу. В конце обработки текста находим наибольшее значение и показываем как результат его ключ те самый популярый омоним. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maximum_and_average_number_of_homonyms_in_the_text_word_forms(text):\n",
    "    # максимальное и среднее число омонимов у словоформ текста\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    result = {}\n",
    "    max_homonym = 0\n",
    "    mean_homonym = 0\n",
    "    counter = 0\n",
    "    clear_text = no_one_symbol_text(make_clear_text(text))\n",
    "    for j in clear_text:\n",
    "        if j not in result:\n",
    "            result[j] = 0\n",
    "        m = morph.parse(j)\n",
    "        length = len([y for y in m if 'Fixd' not in y.tag])\n",
    "        if length > 1 and morph.word_is_known(j):\n",
    "            result[j] += 1\n",
    "            counter += 1\n",
    "            mean_homonym += length\n",
    "            if length > max_homonym:\n",
    "                max_homonym = length\n",
    "                wordform_with_max_homonym = j\n",
    "    print(\"Максимальное число омонимов у словоформ: \", max_homonym)\n",
    "    print(\"Среднее число омонимов у словоформ: \", mean_homonym/counter)\n",
    "    print(\"Словоформа с наибольшим числом омонимов: \", wordform_with_max_homonym)\n",
    "    print(\"Наиболее частотный омоним: \",  max(result, key=result.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Анализ текстов:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь применим все написанные функции к текстам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Научный текст (\"Физиологии человека\" под  редакцией В. М. Покровского, Г. Ф. Коротько)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число различных словоформ:  4409\n",
      "Количество уникальных лемм:  2277\n",
      "Общее количество словоупотреблений:  14290\n",
      "Коэффициент лексического богатства текста: 0.15934219734079777\n",
      "Число незнакомых слов:  412\n",
      "Абсолютная частота омонимичных словоформ с учетом неизменяемых слов:  2289\n",
      "Относительная частота омонимичных словоформ с учетом неизменяемых слов:  0.1601819454163751\n",
      "Абсолютная частота омонимичных словоформ без учета неизменяемых слов:  2221\n",
      "Относительная частота омонимичных словоформ без учета неизменяемых слов:  0.15542337298810358\n",
      "Абсолютная частота словоформ с лексико-морфологической омонимией:  592\n",
      "Относительная частота словоформ с лексико-морфологической омонимией:  0.04142757172848146\n",
      "Максимальное число омонимов у словоформ:  13\n",
      "Среднее число омонимов у словоформ:  3.0057971014492755\n",
      "Словоформа с наибольшим числом омонимов:  любой\n",
      "Наиболее частотный омоним:  на\n"
     ]
    }
   ],
   "source": [
    "count_different_word_forms(scientific_text)\n",
    "lexical_richness_of_the_text_index(scientific_text)\n",
    "number_of_unknown_words(scientific_text)\n",
    "frequency_homonymous_word_forms_full(scientific_text)\n",
    "frequency_homonymous_word_forms(scientific_text)\n",
    "frequency_of_word_forms_with_lexicalmorphological_homonymy(scientific_text)\n",
    "maximum_and_average_number_of_homonyms_in_the_text_word_forms(scientific_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Художественный текст (\"Гранатовый браслет\" А. И. Куприн)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число различных словоформ:  5555\n",
      "Количество уникальных лемм:  3565\n",
      "Общее количество словоупотреблений:  14069\n",
      "Коэффициент лексического богатства текста: 0.2533939867794442\n",
      "Число незнакомых слов:  99\n",
      "Абсолютная частота омонимичных словоформ с учетом неизменяемых слов:  2717\n",
      "Относительная частота омонимичных словоформ с учетом неизменяемых слов:  0.1931196247068022\n",
      "Абсолютная частота омонимичных словоформ без учета неизменяемых слов:  2597\n",
      "Относительная частота омонимичных словоформ без учета неизменяемых слов:  0.18459023384746606\n",
      "Абсолютная частота словоформ с лексико-морфологической омонимией:  974\n",
      "Относительная частота словоформ с лексико-морфологической омонимией:  0.06923022247494491\n",
      "Максимальное число омонимов у словоформ:  13\n",
      "Среднее число омонимов у словоформ:  2.8864577173270254\n",
      "Словоформа с наибольшим числом омонимов:  любой\n",
      "Наиболее частотный омоним:  на\n"
     ]
    }
   ],
   "source": [
    "count_different_word_forms(artistic_text)\n",
    "lexical_richness_of_the_text_index(artistic_text)\n",
    "number_of_unknown_words(artistic_text)\n",
    "frequency_homonymous_word_forms_full(artistic_text)\n",
    "frequency_homonymous_word_forms(artistic_text)\n",
    "frequency_of_word_forms_with_lexicalmorphological_homonymy(artistic_text)\n",
    "maximum_and_average_number_of_homonyms_in_the_text_word_forms(artistic_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тексты примерно выбраны одинакового объема, но после проведения анализа старо очевидно, что художественный текст содержит более чем на 1000 больше различных словоформ, по сравнению с научным текстом. Соответственно и уникальных лемм у него больше. \n",
    "\n",
    "Коэффициент лингвистического богатства художественного текста больше в 1.6 раз! \n",
    "\n",
    "Однако научный текст обладает большим количеством незнакомых слов, что и следовало ожидать. Разница огромна, научный текст имеет в ~4 раза больше незнакомых слов по сравнению с художественным текстом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**С учетом неизменяемых слов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Научный текст**\n",
    "\n",
    "        Абсолютная частота омонимичных словоформ:  2289\n",
    "\n",
    "        Относительная частота омонимичных словоформ:  0.16\n",
    "\n",
    "**Художественный текст**\n",
    "\n",
    "        Абсолютная частота омонимичных словоформ:  2717\n",
    "\n",
    "        Относительная частота омонимичных словоформ:  0.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь не наблюдается колоссальной разницы, но все же относительная частота показывает, что художественный текст более\n",
    "богат омонимичными словоформами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Без учета неизменяемых слов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Научный текст**\n",
    "\n",
    "        Абсолютная частота омонимичных словоформ:  2221\n",
    "        Относительная частота омонимичных словоформ:  0.16\n",
    "\n",
    "**Художественный текст**\n",
    "\n",
    "        Абсолютная частота омонимичных словоформ:  2597\n",
    "        Относительная частота омонимичных словоформ:  0.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут разница между значениями стала меньше. Относительная частота художественного текста уменьшилась. Делаем вывод, что неизменяемые слова вносят более существенный вклад в художественный текст, и служат неким признаком художественного жанра."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Научный текст**\n",
    "\n",
    "\n",
    "        Абсолютная частота словоформ с лексико-морфологической омонимией:  592\n",
    "        Относительная частота словоформ с лексико-морфологической омонимией:  0.04\n",
    "        \n",
    "**Художественный текст**\n",
    "   \n",
    "        Абсолютная частота словоформ с лексико-морфологической омонимией:  974\n",
    "        Относительная частота словоформ с лексико-морфологической омонимией:  0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае подтверждается гипотеза о том, что художественный текст более богат словоформами с омонимией. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Научный текст**\n",
    "\n",
    "        Максимальное число омонимов у словоформ:  13\n",
    "        Среднее число омонимов у словоформ:  3.0057971014492755\n",
    "        Словоформа с наибольшим числом омонимов:  любой\n",
    "        Наиболее частотный омоним:  на\n",
    "    \n",
    "  **Художественный текст**\n",
    "\n",
    "  \n",
    "        Максимальное число омонимов у словоформ:  13\n",
    "        Среднее число омонимов у словоформ:  2.8864577173270254\n",
    "        Словоформа с наибольшим числом омонимов:  любой\n",
    "        Наиболее частотный омоним:  на\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удивительно, но характер самих омонимов в данном эксперименте почти не отличается!\n",
    "\n",
    "В процессе выполнения задания я использовала тестовые кусочки различных текстов, они были на много меньше по объему чем те, на которых проведены данные эксерименты. На таких небольших данных характер самих омонимимичных словоформ (максимальное число омонимов у словоформ, среднее число омонимов и т.д.) сильно отличается. Поэтому возможно имеет смысл проводить эксперименты как на всем тексте, так и на отдельных выборках. \n",
    "\n",
    "Эксперимент показал, что используя данный подход к анализу текстов, можно получить данные для классификации по жанрам. В дальнейшем определять тип жанра нового текста используя машинное обучение. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
